
# AG News Klassifikator mit OpenAI API und Docker

Dieses Projekt implementiert einen Textklassifikator, der mithilfe des **AG News Dataset** Nachrichtenartikel in vier Kategorien klassifiziert: **World**, **Business**, **Sports** und **Science/Technology**. Die Klassifikation erfolgt entweder durch ein **OpenAI LLM** (wie GPT-3.5) oder ein anderes Sprachmodell.

## ðŸš€ Features

- Textklassifikation auf Basis des **AG News Datasets**.
- Klassifikation in 4 Kategorien:
  - ðŸŒ World
  - ðŸ¦ Business
  - âš½ Sports
  - ðŸ§ª Science/Technology
- OpenAI-gestÃ¼tztes Modell (ChatGPT).
- REST API zur Klassifikation von Texten.
- GUI zur Interaktion mit dem Modell.
- Docker-Container fÃ¼r die AusfÃ¼hrung.
- GitHub Actions fÃ¼r Continuous Integration.

## ðŸ“¦ Projektstruktur

```bash
tinyllm-api/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ docker-build.yml          â† GitHub Actions Workflow fÃ¼r Docker Build
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                       â† Flask REST API und GUI
â”‚   â”œâ”€â”€ model_handler.py              â† OpenAI API-Integration fÃ¼r die Klassifikation
â”‚   â”œâ”€â”€ test_with_dataset.py          â† Testskript, das das AG News Dataset mit dem Modell validiert
â”‚   â”œâ”€â”€ index.html                    â† Landing Page fÃ¼r den Klassifikator
â”‚   â””â”€â”€ gui.html                      â† GUI fÃ¼r die Klassifikation von Texten
â”œâ”€â”€ .env                              â† Umgebungsvariablen wie OpenAI API Key
â”œâ”€â”€ Dockerfile                        â† Dockerfile zur Erstellung des Docker-Containers
â”œâ”€â”€ requirements.txt                  â† Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ VERSION                           â† Version des Projekts
â””â”€â”€ README.md                         â† Diese Datei
```

## ðŸ› ï¸ Setup

### 1. Repository Klonen

Zuerst solltest du das Repository auf deinem lokalen Rechner klonen:

```bash
git clone https://github.com/your-username/tinyllm-api.git
cd tinyllm-api
```

### 2. Docker Installation

Stelle sicher, dass Docker auf deinem System installiert ist. Falls nicht, kannst du Docker [hier herunterladen](https://www.docker.com/get-started).

### 3. Docker-Image bauen

Baue das Docker-Image mit dem folgenden Befehl:

```bash
docker build -t textclassifier-openai .
```

Dieser Befehl lÃ¤dt die notwendigen AbhÃ¤ngigkeiten und stellt sicher, dass die Umgebung fÃ¼r die Flask-Anwendung und das Modell korrekt konfiguriert ist.

### 4. Docker-Container starten

Starte den Docker-Container mit dem folgenden Befehl:

```bash
docker run -e OPENAI_API_KEY=sk-your-openai-api-key -p 5050:5050 textclassifier-openai
```

- Ersetze `sk-your-openai-api-key` durch deinen tatsÃ¤chlichen OpenAI API-Key. Du kannst den Key auch sicher mit einer `.env`-Datei und der Option `--env-file` Ã¼bergeben, wenn du ihn nicht direkt in der Kommandozeile angeben mÃ¶chtest.

- Der Port 5050 wird vom Flask-Server verwendet. Wenn du den Port Ã¤ndern mÃ¶chtest, Ã¤ndere die `EXPOSE`-Zeile im Dockerfile.

---

## ðŸ’» API verwenden

Die REST API stellt einen Endpunkt `/predict` zur VerfÃ¼gung, der Texte klassifiziert.

### Beispiel-Request:

```bash
curl -X POST http://localhost:5050/predict -H "Content-Type: application/json" -d '{"text": "NASA announces new mission to Mars."}'
```

### Beispiel-Antwort:

```json
{
  "category": "Science/Technology",
  "input": "NASA announces new mission to Mars."
}
```

---

## ðŸ–¥ï¸ GUI verwenden

Die Anwendung enthÃ¤lt auch eine einfache GUI, die Ã¼ber die Route `/gui` erreichbar ist. Du kannst mit dieser GUI Texte eingeben und vorhersagen lassen.

### Um die GUI zu Ã¶ffnen:

Gehe zu `http://localhost:5050/gui` in deinem Webbrowser.

---

## ðŸš€ Testen der AG News Klassifikation

Um die AG News Klassifikation zu testen, kannst du das Testskript ausfÃ¼hren. Es wird eine kleine Stichprobe des AG News Datasets geladen und die Vorhersagen des Modells mit den tatsÃ¤chlichen Kategorien verglichen.

```bash
docker run --rm textclassifier-openai python app/test_with_dataset.py
```

### Beispiel-Ausgabe:

```bash
Text: Fears for T N pension after talks...
Prediction: Business | Ground Truth: Business

Text: The Race is On: Second Private Team...
Prediction: Science/Technology | Ground Truth: Science/Technology

Accuracy on sample: 9/10 = 0.90
```

---

## ðŸ“„ ErklÃ¤rung der wichtigsten Dateien

### `.github/workflows/docker-build.yml`

Diese Datei enthÃ¤lt den **GitHub Actions Workflow**, der bei jedem Push auf den `main`-Branch ausgelÃ¶st wird. Er fÃ¼hrt den Build-Prozess des Docker-Images aus und startet anschlieÃŸend den AG News Test. Der OpenAI API-Key wird dabei sicher Ã¼ber **GitHub Secrets** Ã¼bergeben.

### `app/main.py`

Hier wird die **Flask-Anwendung** gestartet. Sie stellt zwei Haupt-Routen zur VerfÃ¼gung:
- `/predict`: Akzeptiert Text und gibt die Kategorie des Artikels zurÃ¼ck.
- `/random`: Gibt zufÃ¤llig einen Artikel aus dem AG News Dataset zurÃ¼ck.

### `app/model_handler.py`

In dieser Datei wird das Modell von OpenAI integriert, um Texte zu klassifizieren. Der **API-Key** wird Ã¼ber die Umgebungsvariable `OPENAI_API_KEY` bereitgestellt.

### `app/test_with_dataset.py`

Das Skript lÃ¤dt eine kleine Stichprobe aus dem **AG News Dataset** und testet, wie gut das Modell bei der Vorhersage der richtigen Kategorie abschneidet.

---

## ðŸ’¡ ErweiterungsmÃ¶glichkeiten

- **Modellwahl**: Statt OpenAI kÃ¶nnte ein anderes Modell von Huggingface verwendet werden (z.B. BERT, GPT-2).
- **GUI-Erweiterung**: Eine MÃ¶glichkeit zur Anzeige der Vorhersagegenauigkeit und eine detailliertere BenutzeroberflÃ¤che.
- **Skalierung**: Derzeit lÃ¤uft die Anwendung auf `localhost:5050`. FÃ¼r eine echte Produktionsumgebung kann sie in einem Cloud-Service wie **AWS** oder **Heroku** bereitgestellt werden.
- **Datenbankintegration**: Speichere Klassifikationsergebnisse oder Artikel in einer Datenbank, um eine grÃ¶ÃŸere Datenanalyse zu ermÃ¶glichen.

---

## ðŸ§ª CI/CD und GitHub Actions

### 1. Workflow auslÃ¶sen

Der Workflow wird bei jedem **Push auf den `main`-Branch** automatisch ausgelÃ¶st. Sobald du deinen Code in den GitHub-Repository pushst, wird das Docker-Image gebaut und der Test ausgefÃ¼hrt.

```bash
git add .
git commit -m "Update Workflow and Dockerfile"
git push origin main
```

### 2. GitHub Actions-Logs Ã¼berprÃ¼fen

Gehe auf **GitHub â†’ Dein Repository â†’ Actions**, um den Status des Workflows zu Ã¼berprÃ¼fen.

---

## ðŸ“ Lizenz

Dieses Projekt steht unter der **MIT-Lizenz**.

---

## âœ¨ Autor

> Erstellt von [Laurenziu B.] â€“ im Rahmen eines Ãœbungsprojekts zur Textklassifikation mit **OpenAI GPT-3**, **Flask** und **Docker**.
